{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-1】利用决策树算法对Iris数据构建决策树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c4353575b4e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz  #提前安装\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "dot_file = 'tree.dot'\n",
    "tree.export_graphviz(clf, out_file = dot_file)\n",
    "with open(\"result\\\\tree.dot\", 'w') as f:\n",
    "    f=export_graphviz(clf, out_file = f,feature_names = ['SL','SW','PL','PW'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "dot_file = 'tree.dot'\n",
    "tree.export_graphviz(clf, out_file = dot_file)\n",
    "with open(\"tree.dot\", 'w') as f:\n",
    "    f = export_graphviz(clf, out_file = None,feature_names = ['SL','SW','PL','PW'])\n",
    "    out = graphviz.Source(f)\n",
    "    out.render(r'result1\\iris') #使用garphviz将决策树转存PDF存放到桌面，文件名叫iris\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree #导入决策树\n",
    "from sklearn.datasets import load_iris #导入datasets创建数组\n",
    "import graphviz #导入决策树可视化模块\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data=iris.data #选择训练数组\n",
    "iris_target=iris.target #选择对应标签数组\n",
    "\n",
    "clf = tree.DecisionTreeClassifier() #创建决策树模型\n",
    "clf=clf.fit(iris_data,iris_target) #拟合模型\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) #以DOT格式导出决策树\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(r'result\\iris') #使用garphviz将决策树转存PDF存放到桌面，文件名叫iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-2】利用KNN对iris数据集分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:,:2]\n",
    "Y = iris.target\n",
    "print(iris.feature_names)\n",
    "cmap_light = ListedColormap(['#FFAAAA','#AAFFAA','#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000','#00FF00','#0000FF'])\n",
    "clf = KNeighborsClassifier(n_neighbors = 10,weights = 'uniform')\n",
    "clf.fit(X,Y)\n",
    "#画出决策边界\n",
    "x_min,x_max = X[:,0].min()-1,X[:,0].max()+1\n",
    "y_min,y_max = X[:,1].min()-1,X[:,1].max()+1\n",
    "xx,yy = np.meshgrid(np.arange(x_min,x_max,0.02),\n",
    "np.arange(y_min,y_max,0.02))\n",
    "Z = clf.predict(np.c_[xx.ravel(),yy.ravel()]).reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx,yy,Z,cmap = cmap_light)\n",
    "#绘制预测结果图\n",
    "plt.scatter(X[:,0],X[:,1],c = Y,cmap = cmap_bold)\n",
    "plt.xlim(xx.min(),xx.max())\n",
    "plt.ylim(yy.min(),yy.max())\n",
    "plt.title('3_Class(k = 10,weights = uniform)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-3】利用SVM对iris数据集分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data,iris.target\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, random_state = 1, test_size = 0.2)\n",
    "classifier=svm.SVC(kernel='linear',gamma=0.1,decision_function_shape='ovo',C=0.1)\n",
    "classifier.fit(x_train, y_train.ravel())\n",
    "print(\"SVM-输出训练集的准确率为：\", classifier.score(x_train, y_train))\n",
    "print(\"SVM-输出测试集的准确率为：\", classifier.score(x_test, y_test))\n",
    "y_hat = classifier.predict(x_test)\n",
    "classreport = metrics.classification_report(y_test,y_hat)\n",
    "print(classreport)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-4】对iris数据集进行朴素贝叶斯分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "iris = load_iris()\n",
    "clf = GaussianNB()#设置分类器\n",
    "clf.fit(iris.data,iris.target)#训练分类器\n",
    "y_pred = clf.predict(iris.data)#预测\n",
    "print(\"Number of mislabeled points out of %d points:%d\" %(iris.data.shape[0],(iris.target != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-5】sklearn实现iris数据K-Means聚类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris  \n",
    "from sklearn.cluster import KMeans  \n",
    "iris = load_iris()    \n",
    "#加载数据集\n",
    "X = iris.data  \n",
    "estimator = KMeans(n_clusters = 3)    \n",
    "#构造K-Means聚类模型\n",
    "estimator.fit(X)                                   \n",
    "#数据导入模型进行训练\n",
    "label_pred = estimator.labels_            \n",
    "#获取聚类标签\n",
    "print(label_pred)\n",
    "#显示各个样本所属的类别标签\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-6】Python层次聚类实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle  #python自带的迭代器模块\n",
    "#产生随机数据的中心\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "#产生的数据个数\n",
    "n_samples = 3000\n",
    "#生产数据\n",
    "X, lables_true = make_blobs(n_samples = n_samples, centers= centers, cluster_std = 0.6,random_state = 0)\n",
    "#设置分层聚类函数\n",
    "linkages = ['ward', 'average', 'complete']\n",
    "n_clusters_ = 3\n",
    "ac = AgglomerativeClustering(linkage = linkages[2],n_clusters = n_clusters_)\n",
    "#训练数据\n",
    "ac.fit(X)\n",
    "#每个数据的分类\n",
    "lables = ac.labels_\n",
    "plt.figure(1)  #绘图\n",
    "plt.clf()\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    #根据lables中的值是否等于k，重新组成一个True、False的数组\n",
    "    my_members = lables == k\n",
    "    #X[my_members, 0]取出my_members对应位置为True的值的横坐标\n",
    "    plt.plot(X[my_members, 0], X[my_members, 1], col + '.')    \n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-7】DBSCAN算法实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "def findNeighbor(j,X,eps):\n",
    "    N = []\n",
    "    for p in range(X.shape[0]):   #找到所有邻域内对象\n",
    "        temp = np.sqrt(np.sum(np.square(X[j]-X[p])))   #欧氏距离\n",
    "        if(temp<=eps):\n",
    "            N.append(p)\n",
    "    return N\n",
    "def dbscan(X,eps,min_Pts):\n",
    "    k = -1\n",
    "    NeighborPts = []      #array,某点领域内的对象\n",
    "    Ner_NeighborPts = []\n",
    "    fil = []                #初始时已访问对象列表为空\n",
    "    gama = [x for x in range(len(X))] #初始时将所有点标记为未访问\n",
    "    cluster = [-1 for y in range(len(X))]\n",
    "    while len(gama)>0:\n",
    "        j = random.choice(gama)\n",
    "        gama.remove(j)  #未访问列表中移除\n",
    "        fil.append(j)   #添加入访问列表\n",
    "        NeighborPts = findNeighbor(j,X,eps)\n",
    "        if len(NeighborPts) < min_Pts:\n",
    "            cluster[j] = -1   #标记为噪声点\n",
    "        else:\n",
    "            k = k+1\n",
    "            cluster[j] = k\n",
    "            for i in NeighborPts:\n",
    "                if i not in fil:\n",
    "                    gama.remove(i)\n",
    "                    fil.append(i)\n",
    "                    Ner_NeighborPts=findNeighbor(i,X,eps)\n",
    "                    if len(Ner_NeighborPts) >= min_Pts:\n",
    "                        for a in Ner_NeighborPts:\n",
    "                            if a not in NeighborPts:\n",
    "                                NeighborPts.append(a)\n",
    "                    if (cluster[i]==-1):\n",
    "                        cluster[i]=k\n",
    "    return cluster\n",
    "X1, y1 = datasets.make_circles(n_samples=1000, factor=.6,noise=.05)\n",
    "X2, y2 = datasets.make_blobs(n_samples = 300, n_features = 2, centers = [[1.2,1.2]], cluster_std = [[.1]],random_state = 9)\n",
    "X = np.concatenate((X1, X2))\n",
    "eps = 0.08\n",
    "min_Pts = 10\n",
    "C = dbscan(X,eps,min_Pts)\n",
    "plt.figure(figsize = (12, 9), dpi = 80)\n",
    "plt.scatter(X[:,0],X[:,1],c = C)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【例11-8】sklearn实现实现鸢尾花数据进行降维，将原来4维的数据降维为2维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 \n",
    "from sklearn.decomposition import PCA          \n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "y = data.target\n",
    "x = data.data\n",
    "pca = PCA(n_components = 2)     \n",
    "#加载PCA算法，设置降维后主成分数目为2\n",
    "reduced_x = pca.fit_transform(x)   #对样本进行降维\n",
    "reduced_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_x,red_y = [],[]\n",
    "blue_x,blue_y = [],[]\n",
    "green_x,green_y = [],[]\n",
    "for i in range(len(reduced_x)):\n",
    "    if y[i] ==0:\n",
    "        red_x.append(reduced_x[i][0])\n",
    "        red_y.append(reduced_x[i][1])\n",
    "    elif y[i]==1:\n",
    "        blue_x.append(reduced_x[i][0])\n",
    "        blue_y.append(reduced_x[i][1])\n",
    "    else:\n",
    "        green_x.append(reduced_x[i][0])\n",
    "        green_y.append(reduced_x[i][1])\n",
    "plt.scatter(red_x,red_y,c='r',marker='x')\n",
    "plt.scatter(blue_x,blue_y,c='b',marker='D')\n",
    "plt.scatter(green_x,green_y,c='g',marker='.')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
